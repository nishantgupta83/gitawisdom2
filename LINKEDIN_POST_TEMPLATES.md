# LinkedIn Post Templates for GitaWisdom Teaching Series

## Template Philosophy

These templates are designed to:
1. **Reduce blank page anxiety** - Fill in the blanks instead of starting from scratch
2. **Maintain authentic voice** - Structured but not robotic
3. **Ensure engagement** - Proven hook ‚Üí story ‚Üí lesson ‚Üí CTA pattern
4. **Provide safety** - Factual code/metrics reduce opinion-based vulnerability

## Template 1: The Bug Story (High Engagement)

**Best for**: Critical bugs caught by agents, compliance issues, production near-misses

**Structure**:
```
[SHOCKING OPENING - Quantified impact]
[One sentence that makes people stop scrolling]

[THE SETUP - What you were building]
[2-3 sentences of context]

[THE BUG - Show the bad code]
```dart
// What I wrote (WRONG):
[5-10 lines of buggy code with inline comment showing mistake]
```

[THE DISCOVERY - How you found it]
[Agent name] flagged this during [review type]:
```
[Agent output with emoji formatting]
‚ö†Ô∏è CRITICAL: [Issue description]
Location: [File path:line number]
Impact: [Business/compliance consequence]
```

[THE FIX - Show the correct code]
```dart
// What it should be (CORRECT):
[5-10 lines of fixed code with inline comment showing fix]
```

[THE LESSON - PM takeaway]
[2-3 sentences about WHEN to use this pattern, not HOW to code it]

[ENGAGEMENT QUESTION]
What's the [superlative] bug that [impact] in your product? Share your story in comments.
```

**Example**:

```
A single word typo almost got our app removed from Google Play. Here's the compliance bug I almost shipped.

I was implementing Google Play's 2024 requirement: users must be able to delete their account AND all data from within the app. Straightforward, right?

```dart
// My account deletion code (WRONG):
final boxesToDelete = [
  'journal_entries',
  'user_bookmarks',  // ‚ùå This box doesn't exist!
  'user_progress',
];
```

Code Reviewer Agent flagged this during pre-production review:
```
‚ö†Ô∏è CRITICAL: Account deletion references non-existent Hive box
Location: lib/screens/more_screen.dart:475
Impact: Deletion will fail ‚Üí Google Play compliance violation ‚Üí App removal
```

The actual box name was 'bookmarks' (not 'user_bookmarks'):

```dart
// Fixed code (CORRECT):
final boxesToDelete = [
  'journal_entries',
  'bookmarks',  // ‚úÖ Correct box name
  'user_progress',
];
```

PM Lesson: I assumed the box name without verifying it in the actual codebase. This is why code review (human OR AI) is non-negotiable for compliance-critical features.

What's the smallest bug that had the biggest impact in your product? Share your story.
```

---

## Template 2: The Performance Optimization (Product-First, Data-Driven)

**Best for**: Startup time improvements, caching strategies, memory optimizations

**Structure**:
```
[PRODUCT PROBLEM HOOK - User-facing pain with metric]
[One sentence describing user frustration with quantified impact]

[THE BUSINESS CONTEXT - Why this matters]
[User feedback, NPS impact, or competitive pressure - 2-3 sentences]

[THE DATA ANALYSIS - What you discovered]
[Usage logs showing actual user behavior vs assumptions]

[THE PM DECISION FRAMEWORK - Your reasoning]
Question 1: What's the minimum data needed for good UX?
- Data-driven answer: [insight from logs]

Question 2: What's the cost of optimizing for 100% vs 80% use case?
- Trade-off analysis: [cost comparison]

[THE DECISION - What you chose and why]
[Specific choice with rationale]

[THE OUTCOME - Business impact]
- User metric: [e.g., NPS increase, session time]
- Technical metric: [e.g., 70% faster startup]
- Cost metric: [e.g., $816/year savings]

[PM SKILLS APPLIED]
1. Data Analysis: [specific insight]
2. Trade-off Evaluation: [what you balanced]
3. User Empathy: [what user perception you optimized for]

[ENGAGEMENT QUESTION]
How do you decide what to optimize? Data-driven or user complaints?

---

### üì¶ Technical Implementation (For the Curious)

<details>
<summary><b>How I Actually Built This: [Architecture Name]</b></summary>

[THE TECHNICAL SOLUTION - Code implementation]
```dart
// Before (SLOW):
[5-10 lines showing old approach]
// Total: [time] üêå

// After (FAST):
[5-10 lines showing new approach]
// Total: [time] ‚ö°
```

[THE IMPACT - Real device testing]
| Device | Before | After | Improvement |
|--------|--------|-------|-------------|
| [Device 1] | [time] | [time] | [%] |
| [Device 2] | [time] | [time] | [%] |

</details>
```

**Example**:

```
Users were uninstalling GitaWisdom before it even loaded. I analyzed 30 days of session data and discovered the real problem.

**The Product Problem**:
- Users tap the app icon ‚Üí stare at blank screen for 4.1 seconds
- **Result**: 23% uninstall rate within first 24 hours

**The Business Context**:
App Store reviews were brutal: "Too slow to open", "Hangs on startup". Our 4.2‚≠ê rating was dropping. Competitors with simpler content were getting 4.7‚≠ê because they felt faster.

**The Data Discovery**:
I pulled startup logs from our analytics:
```
üìä What's Actually Slowing Us Down (v1.0):
   Database init: 800ms (necessary)
   Opening 12 storage boxes: 1,200ms (is this needed?)
   Backend connection: 900ms (can this wait?)
   Loading 1,226 scenarios: 1,200ms (do users need all of this?)

üí° User Behavior Reality:
   Average scenarios viewed in first session: 1-2 (not 1,226!)
```

**PM Decision Framework**:

Question 1: What's the MINIMUM data for a good first impression?
- Data-driven answer: Just 1 scenario. Users don't browse 1,226 scenarios‚Äîthey read 1-2 and leave.

Question 2: What can be deferred without breaking UX?
- Analysis: Backend connection and full scenario catalog don't block the first screen. Move them to background.

**The Decision**:
Load only what's visible on first screen. Everything else happens in background while user is reading.

**The Outcome**:
- User metric: 4.1s ‚Üí 1.2s perceived load time (70% faster)
- Business metric: Uninstall rate dropped to 8% (65% reduction)
- App Store rating: Climbed to 4.6‚≠ê

**PM Skills Applied**:
1. Data Analysis: Session logs revealed users view 1-2 scenarios, not 1,226
2. Trade-off Evaluation: Balanced "instant UX" vs "complete offline data"
3. User Empathy: "Instant" matters more than "fully loaded"

How do you decide what to optimize? Data-driven or user complaints?

---

### üì¶ Technical Implementation (For the Curious)

<details>
<summary><b>How I Actually Built This: Progressive Lazy Loading Architecture</b></summary>

**The fix wasn't faster code - it was smarter prioritization:**

```dart
// Before (SLOW): Load everything sequentially
await Hive.initFlutter();           // 800ms
await openAllBoxes();               // 1,200ms (12 boxes!)
await supabase.initialize();        // 900ms
await loadScenarios();              // 1,200ms (1,226 scenarios!)
// Total: 4,100ms üêå

// After (FAST): Load only critical path, defer the rest
await Hive.initFlutter();           // 800ms
await openSettingsBox();            // 50ms (just 1 box)
await loadCriticalCache();          // 350ms (50 scenarios)
// Total: 1,200ms ‚ö°

unawaited(supabase.initialize());   // Non-blocking background
unawaited(loadCompleteCache());     // Background load remaining 1,176
```

**Real device results**:
| Device | v1.0 | v3.0 | Improvement |
|--------|------|------|-------------|
| Pixel 4a (4GB RAM) | 4.8s | 1.5s | 69% faster |
| iPhone 12 | 3.7s | 1.0s | 73% faster |
| Pixel 3a (3GB RAM) | 5.6s | 1.8s | 68% faster |

</details>
```

---

## Template 3: The Decision Framework (Strategy Focus)

**Best for**: Trade-off analysis, stakeholder decisions, "why NOT to build" stories

**Structure**:
```
[CONTRARIAN HOOK - Decision that seems wrong but was right]
[Frame the counterintuitive choice]

[THE CONTEXT - What led to this decision]
[2-3 sentences of situation]

[THE FRAMEWORK - Show your decision matrix]
| Factor | Option A | Option B |
|--------|----------|----------|
| [Criterion 1] | [Value] | [Value] |
| [Criterion 2] | [Value] | [Value] |
| **Decision** | [‚úÖ/‚ùå] | [‚úÖ/‚ùå] |

[THE TRADE-OFFS - What you gave up]
[Honest assessment of costs]

[THE OUTCOME - What happened]
[Retrospective with metrics or qualitative results]

[THE PRINCIPLE - When to use this framework]
[2-3 sentences about reusable decision pattern]

[ENGAGEMENT QUESTION]
Which decision framework do you use for [type of decision]? Share in comments.
```

**Example**:

```
I spent 3 months building an iOS app I never shipped. Here's why killing it was the best decision.

GitaWisdom v1.0 was a beautiful Swift/UIKit app. Native iOS, smooth animations, 4,200 lines of carefully crafted code. Then I abandoned it and rebuilt in Flutter.

Decision Matrix:
| Factor | Native iOS | Flutter Cross-Platform |
|--------|------------|------------------------|
| Time to Android | +6 months | +2 weeks |
| Maintenance Cost | 2x codebases | 1 codebase |
| Feature Parity | Manual duplication | Automatic |
| Platform Features | Full native access | 95% via plugins |
| **Decision** | ‚ùå Abandon | ‚úÖ Rebuild |

What I Gave Up:
- 3 months of development time (sunk cost)
- Some platform-specific UI polish (iOS 3D Touch, etc.)
- My emotional attachment to "native is always better"

What I Gained:
- Android version shipped in 2 weeks (vs 6 months)
- One codebase to maintain (vs two diverging apps)
- 70% faster iteration cycle (build once, test on both platforms)

Decision Principle: Use this framework when facing the "sunk cost fallacy trap":
1. Does continuing serve FUTURE value or justify PAST effort?
2. What's the opportunity cost of the path not taken?
3. Can you reuse learnings even if you abandon code?

For GitaWisdom, the iOS-specific features weren't differentiators. Cross-platform speed was.

Which decision framework do you use for "build vs rebuild" decisions? Share your approach.
```

---

## Template 4: The Agent Orchestration (AI-Powered PM)

**Best for**: Five-agent system, AI-assisted development, "PM without coding" positioning

**Structure**:
```
[PROVOCATIVE HOOK - Challenge traditional PM role]
[Statement that makes technical PMs react]

[THE TRADITIONAL APPROACH - Old way]
[2-3 sentences describing manual/human-only process]

[THE AGENT APPROACH - New way]
[List of agents and their roles]

[THE WORKFLOW - Show orchestration]
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [Step 1: PM defines WHAT/WHY]       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
[Visual diagram of agent workflow with arrows]
```

[THE REAL EXAMPLE - Concrete case]
[Specific instance where agent caught/improved something]

[THE VALUE - Economic or quality impact]
[Comparison to human-only approach]

[THE NUANCE - When this works/doesn't work]
[2-3 sentences about limitations and PM judgment required]

[ENGAGEMENT QUESTION]
Are you using AI agents in your product workflow? What's working (or not)?
```

**Example**:

```
I don't write performant code. I orchestrate 5 AI agents who do it for me.

Traditional PM Approach:
1. Write requirements doc
2. Hand off to engineering
3. Hope they catch edge cases
4. React to bugs in production

My Agent Orchestration:
1. **Android Performance Engineer** - Prevents ANR crashes, optimizes memory
2. **iOS Performance Engineer** - ProMotion displays, battery management
3. **UI/UX Reviewer** - Accessibility compliance, platform guidelines
4. **Code Reviewer** - Bug detection, architectural consistency
5. **Baseline Editor** - Hallucination prevention, fact-checking

Workflow:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PM: Define WHAT and WHY             ‚îÇ
‚îÇ "Users must delete their account    ‚îÇ
‚îÇ  to comply with Google Play 2024"   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Implementation (PM + AI pairing)    ‚îÇ
‚îÇ Write account deletion code         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Agent Review (parallel execution)   ‚îÇ
‚îÇ ‚îú‚îÄ Android: Check data clearing     ‚îÇ
‚îÇ ‚îú‚îÄ iOS: Verify secure storage       ‚îÇ
‚îÇ ‚îú‚îÄ Code: Validate box names         ‚îÇ ‚Üê Caught 'user_bookmarks' bug
‚îÇ ‚îî‚îÄ Baseline: Challenge assumptions  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PM: Decide which fixes to accept    ‚îÇ
‚îÇ "Fix box name: YES (compliance)     ‚îÇ
‚îÇ  Refactor architecture: NO (scope)" ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Real Example: Code Reviewer caught my bookmark box name bug ('user_bookmarks' vs 'bookmarks') that would've failed Google Play compliance. A human code reviewer might've caught it too - but not at 2am when I was implementing the feature.

Value Proposition:
| Resource | Annual Cost | Availability |
|----------|-------------|--------------|
| 2 Senior Engineers | ~$300,000 | 40 hrs/week |
| 5 AI Agents | ~$2,400 | 24/7 |

The Nuance: Agents aren't autonomous. They're force multipliers. I still decide WHAT to build, WHY it matters, and WHICH agent recommendations to accept. I just don't need to know HOW to optimize ProMotion displays myself - I need to know WHEN to ask the iOS Performance Agent to review my display code.

Are you using AI agents in your product workflow? What's working (or not)?
```

---

## Template 5: The Compliance Gauntlet (Regulatory/Policy Focus)

**Best for**: Google Play requirements, App Store guidelines, security implementations

**Structure**:
```
[COMPLIANCE HOOK - Requirement most people don't know about]
[Specific policy with deadline or consequence]

[THE REQUIREMENT - What the policy says]
[Quote or paraphrase official requirement]

[THE INTERPRETATION - What it means in practice]
[Break down the actual implementation needed]

[THE IMPLEMENTATION - Show the code]
```dart
// What Google Play requires:
[5-15 lines showing compliance code]
```

[THE TESTING - How you verified compliance]
[Checklist or test cases]

[THE EDGE CASES - What almost went wrong]
[1-2 examples of non-obvious requirements]

[THE PM SKILL - How to navigate compliance without legal team]
[Framework for reading and implementing policy requirements]

[ENGAGEMENT QUESTION]
What [platform] compliance challenge have you faced? How did you interpret the requirements?
```

**Example**:

```
Google Play's 2024 policy requires in-app account deletion. Here's what "delete all data" actually means.

The Requirement (Google Play Data Safety):
"Apps that enable account creation must also allow users to initiate account deletion from within the app, and must delete all associated user data upon request."

The Interpretation:
"All associated user data" isn't just the user record. It's every piece of data tied to that user across your entire local and remote storage.

The Implementation:
```dart
// Google Play's "all data" means ALL 12 local storage boxes:
final boxesToDelete = [
  'journal_entries',      // User-generated content
  'bookmarks',            // User preferences
  'user_progress',        // User state
  'settings',             // User config
  'scenarios',            // Cached content (tied to user session)
  'scenarios_critical',   // Tier 1 cache
  'scenarios_frequent',   // Tier 2 cache
  'scenarios_complete',   // Tier 3 cache
  'daily_verses',         // Personalized cache
  'chapters',             // User-specific chapter data
  'chapter_summaries',    // Chapter overview cache
  'search_cache',         // User search history
];

for (final boxName in boxesToDelete) {
  try {
    await Hive.deleteBoxFromDisk(boxName);
    debugPrint('üóëÔ∏è Deleted: $boxName');
  } catch (e) {
    debugPrint('‚ö†Ô∏è Could not delete $boxName: $e');
    // Best-effort deletion: Continue with other boxes
  }
}

// Also delete from remote Supabase database
await supabase.auth.admin.deleteUser(userId);
```

The Testing Checklist:
- [ ] Account deletion button visible to authenticated users
- [ ] Confirmation dialog warns about permanent deletion
- [ ] All 12 Hive boxes removed from device storage
- [ ] User record deleted from Supabase auth.users table
- [ ] User data deleted from custom tables (journal_entries, etc.)
- [ ] App functions correctly after deletion (guest mode)

The Edge Case That Almost Failed:
I initially only deleted 4 boxes (user_progress, settings, journal_entries, bookmarks). An auditor could argue that cached scenarios are "associated data" because they're personalized to the user's session. Better safe than rejected - I delete all 12 boxes now.

PM Compliance Framework:
1. Read the exact policy wording (not blog summaries)
2. Interpret "edge case" broadly (assume strictest interpretation)
3. Implement with detailed logging (prove compliance in review)
4. Test on actual devices (emulators miss platform-specific issues)
5. Document your interpretation (for when reviewer asks questions)

What Google Play or App Store compliance challenge have you faced? How did you interpret the requirements?
```

---

## Visual Content Guidelines

### Code Snippet Formatting
```dart
// Use syntax highlighting (LinkedIn supports it in code blocks)
// Add inline comments to explain WHY, not WHAT
// Keep snippets to 5-15 lines (anything longer, link to GitHub)
// Use emoji to highlight key lines:
final boxName = 'user_bookmarks';  // ‚ùå WRONG: Box doesn't exist
final boxName = 'bookmarks';       // ‚úÖ CORRECT: Actual box name
```

### Performance Tables
Use LinkedIn's table markdown for clean formatting:
```
| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Startup | 4.1s | 1.2s | 70% faster |
| Memory | 180MB | 60MB | 66% less |
| API calls | 50K/mo | 1K/mo | 98% fewer |
```

### Agent Output Boxes
Format agent feedback as indented code blocks with emoji:
```
‚ö†Ô∏è CRITICAL: [Issue]
Location: [File path:line number]
Impact: [Consequence]
Severity: [HIGH/MEDIUM/LOW]
Fix: [Recommendation]
```

### Diagrams (ASCII Art)
Keep workflow diagrams simple with box-drawing characters:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Step 1    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Step 2    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Voice & Tone Checklist

Before posting, verify:
- [ ] **Authentic**: Sounds like you talking, not corporate PR
- [ ] **Humble**: Acknowledges mistakes and limitations
- [ ] **Specific**: Uses real metrics, file paths, line numbers
- [ ] **Educational**: Teaches a reusable principle, not just a story
- [ ] **Accessible**: Technical depth without requiring CS degree
- [ ] **Engaging**: Asks a question that invites genuine discussion

## Anti-Pattern Warning Signs

**Don't post if your draft**:
- Uses vague metrics ("much faster" instead of "70% faster")
- Lacks code snippets (just talking about code, not showing it)
- Sounds defensive ("I know this might not be the best approach, but...")
- Name-drops tools without explaining why ("We use Supabase and Hive")
- Ends with generic CTA ("What do you think?" instead of specific question)

## Emergency Simplification

**If you're stuck in editing loop** (>5 revisions):
1. Delete everything except the code snippet
2. Write ONE sentence: "This [worked/didn't work] because [reason]"
3. Write ONE question: "Have you seen [similar problem]?"
4. Post it

**Example**:
```
This code almost got our app removed from Google Play:

```dart
final boxesToDelete = [
  'user_bookmarks',  // ‚ùå Wrong box name
];
```

Code review caught the bug before production. Have you had a compliance near-miss?
```

This is a C-grade post, but it's better than no post. You can iterate next time.

---

**Last Updated**: October 6, 2025
**Usage**: Pick template ‚Üí Fill in GitaWisdom example ‚Üí Edit for voice ‚Üí Post
